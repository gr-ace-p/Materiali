# Materiali
## Prima fase di prototipazione: Arduino+sensori+p5.js  ##
#### In questo prototipo utilizzo: un sensore ultrasuoni, un joystick ed un potenziometro per controllare gli assi di variaizone del carattere [+](https://editor.p5js.org/gr.ace/sketches/kET-pmdYl) ####


![anteprima](https://imgur.com/ljHEUlN.gif)


## Seconda fase di prototipazione: Dati microfono ##
#### In questo secondo prototipo sfrutto gli input ricevuti dal microfono per controllare due assi di variazione del carattere on base all'intensit√† del suono rilevato [+](https://editor.p5js.org/gr.ace/sketches/M1ov0ly79) ####


![anteprima](https://i.imgur.com/IQHQlBn.gif)





## Terza fase di prototipazione: prototipi intelligenti ##
#### In questo caso utilizzo la libreria ml5.js per permettere all'algoritmo di riconoscere il mio volto assegnando agli assi di variazione del carattere delle dimensioni che variano a seconda della mia distanza dallo schermo, quindi alla grandezza del mio volto.  [+](https://editor.p5js.org/gr.ace/sketches/-YJZEA8sf) ####


![Imgur](https://imgur.com/qSCBBfM.gif)





#### Ho utilizzato in questo caso un algoritmo in grado di riconoscere istante per istante le emozioni rilevate dal mio volto, ogni emozione modifica un asse di variazione del carattere  [+](https://editor.p5js.org/gr.ace/sketches/Ztfd3xQNy) ####


![Imgur](https://imgur.com/U8oVxmz.gif)





#### infine con lo stesso meccanismo ho agito sul colore del carattere ad ogni sentimento rilevato [+](https://editor.p5js.org/gr.ace/sketches/Se3VX-QkU) [+](https://editor.p5js.org/gr.ace/sketches/Q96NWNCD)####


![Imgur](https://imgur.com/BKLMymh.gif)
